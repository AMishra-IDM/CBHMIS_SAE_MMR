mutate(Ward_color_group = as.factor((as.numeric(factor(Ward)) - 1) %% 10 + 1))
p1 <- ggplot(cbhmis_clean,aes(x=time,y=repRate,group=Ward,color=Ward_color_group)) + facet_wrap(~LGA) +
geom_point() + geom_line() + theme_bw() +   theme(legend.position = "none")
p1
## aggregating to LGA level
cbhmis_lga <- cbhmis_clean[,!names(cbhmis_clean) %in% c("Ward","repRate","Ward_color_group","sub_time")] %>%
group_by(time, LGA) %>% summarise(across(everything(), sum))
cbhmis_lga$repRate <- 100*cbhmis_lga$repCVs/cbhmis_lga$totalCVs
p.RR <- ggplot(cbhmis_lga, aes(x = time, y = repRate)) +
geom_line() +
geom_point() +
facet_wrap(~LGA) +
ylab("Reporting Rate") +
scale_x_date(date_labels = "%b %y") +
theme_bw() +
ylim(0, 100) +
theme(
strip.text = element_text(size = 14),      # Facet labels
axis.title = element_text(size = 14),      # Axis labels
axis.text = element_text(size = 12),       # Tick labels
plot.title = element_text(size = 16),      # Title (if you add one)
legend.text = element_text(size = 12),     # Legend text (if present)
legend.title = element_text(size = 14)     # Legend title (if present)
)
png(filename = paste0(outdir,"/plots/repRateMonthly.png"),height=800,width=1400)
p.RR
dev.off()
cbhmis_lga_rep <- cbhmis_lga[,names(cbhmis_lga) %in% c("LGA","repRate")] %>%
group_by(LGA) %>% summarise(across(everything(), mean)) %>%
rename("avgRegRate"="repRate")
repRate <- left_join(kdn_shp,cbhmis_lga_rep,by=c("NAME_2"="LGA"))
pRRmap <- ggplot(repRate) +
geom_sf(aes(fill = avgRegRate)) +
scale_fill_viridis_c() +
geom_sf_text(aes(label = NAME_2 ), size = 4, check_overlap = TRUE,color="white",fontface ="bold") +
theme_void() +
labs(fill = "Average reporting rate",
title = "Reporting Rate for LGA averaged over monthly rates")
png(filename = paste0(outdir,"/plots/repRateMap.png"),height=900,width=1200)
pRRmap
dev.off()
referral_vars <- c("ANC_ref","FP_ref","LD_ref","PNC_ref","PPFP_ref","Imm_ref","Nut_ref","ICMI_ref")
## We load in external population data to scale the referral data
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
getwd()
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
## We load in external population data to scale the referral data
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
list.files()
list.files("/raw data/")
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
## We load in external population data to scale the referral data
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
plot(my_raster)
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
pop_wra <- rast("C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR/raw data/NGA_population_v2_1_agesex_f15_49.tif")
pop_wra
## We load in external population data to scale the referral data
pop_wra <- rast("/raw data/NGA_population_v2_1_agesex_f15_49.tif")
C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR
plot(pop_wra)
boundary <- kdn_shp
boundary$wra_pop <- exact_extract(pop_wra, boundary, 'sum')
pop_dat <- boundary %>%
st_drop_geometry() %>%
as.data.frame() %>% dplyr::select(NAME_2, wra_pop)
pop_dat
sum(pop_dat$wra_pop)
palette23 <- createPalette(23, seedcolors = c("#000000"))
names(palette23) <- unique(cbhmis_lga$LGA)  # Named vector for manual scale
scat.plots <- map(referral_vars, function(var) {
ggplot(cbhmis_lga, aes(x = repRate, y = .data[[var]])) +
geom_point(aes(color = LGA)) +
geom_smooth(
method = "loess",
se = FALSE,
color = "black",
linetype = "dashed") +
scale_color_manual(values = palette23) +
theme_minimal() +
labs(
title = paste(var),
x = "Reporting Rate",
y = "Num. Referrals"
)
})
ref_plot <- wrap_plots(scat.plots, ncol = 3, guides = "collect") &
theme(legend.position = "bottom")
png(filename = paste0(outdir,"/plots/referralplots.png"),height=900,width=1200)
ref_plot
dev.off()
## (2)assuming 5% of women of WRA are pregnant and 70% are attending ANC (gives an upper bound)
outlier.sd <-  cbhmis_lga %>%
group_by(LGA)  %>%
summarise(threeSD = 3*sd(ANC_ref) + mean(ANC_ref, na.rm=T))
outlier.wra <- pop_dat
outlier.wra$preg_women <- outlier.wra$wra_pop*0.05
outlier.wra$anc_max <- outlier.wra$preg_women*0.7
outlier <- left_join(outlier.sd,outlier.wra,by=c("LGA"="NAME_2"))
pANC <- ggplot(cbhmis_lga) +
facet_wrap(~LGA,scales = 'free_y') +
geom_point(aes(x = repRate, y = ANC_ref)) +
geom_hline(data=outlier, aes(yintercept=threeSD, color = "3 SD Threshold")) +
geom_hline(data=outlier, aes(yintercept=anc_max, color = "Max ANC")) +
theme_bw() + xlim(c(0,100)) +
scale_color_manual(values = c("3 SD Threshold" = "blue", "Max ANC" = "green"),name="Outlier Rule")
png(filename = paste0(outdir,"/plots/ANC_ref_outlier.png"),height=900,width=1200)
pANC
dev.off()
cbhmis_lga <- dplyr::left_join(cbhmis_lga,outlier,by=c("LGA"))
## surpress those LGA obs where the obs are above threshold
cbhmis_lga$ANC_ref <- ifelse(cbhmis_lga$ANC_ref > cbhmis_lga$anc_max,NA,cbhmis_lga$ANC_ref)
pANC_remove <- ggplot(cbhmis_lga,aes(x = repRate, y = ANC_ref)) +
geom_point(aes(color = LGA)) +
scale_color_manual(values = palette23) +
geom_smooth(method = "loess", se = FALSE, color = "black",linetype = "dashed") +
theme_bw() + xlim(c(50,100))
png(filename = paste0(outdir,"/plots/ANC_ref_remove.png"),height=900,width=1200)
pANC_remove
dev.off()
### NEEDS FOLLOW_UP: This is not a super strong relationship, so perhaps we need to look at FP -- for now use this one
##### C2: Checking monthly MMR data #####
sd_lines <- cbhmis_lga %>%
group_by(LGA) %>%
summarise(deaths_3sd = 3*sd(deaths, na.rm = TRUE),
lb_3sd = 3*sd(lb, na.rm = TRUE) + mean(lb, na.rm=T),
lb_4sd = 4*sd(lb, na.rm = TRUE) + mean(lb, na.rm=T),)
pMD <- ggplot(data=cbhmis_lga) + facet_wrap(~LGA) + ylab("Maternal Deaths") +
geom_line(aes(x=time,y=deaths)) + geom_point(aes(x=time,y=deaths)) + theme_bw() +
geom_hline(data = sd_lines, aes(yintercept = deaths_3sd,color="3 SD"),
linetype = "dashed") #+ scale_color_manual(values = c("3 SD" = "red"),name="Outlier Rule")
pLB <- ggplot(data=cbhmis_lga,aes(x=time,y=lb)) + facet_wrap(~LGA) + ylab("Live Births") +
geom_line() + geom_point() + theme_bw() +
geom_hline(data = sd_lines, aes(yintercept = lb_3sd,color="3 SD"),
linetype = "dashed") +
geom_hline(data = sd_lines, aes(yintercept = lb_4sd,color="4 SD"),
linetype = "dashed") +
scale_color_manual(values = c("3 SD" = "red","4 SD" = "blue"),name="Outlier Rule")
MMR_line <- pMD + pLB + plot_layout(ncol = 2)
png(filename = paste0(outdir,"/plots/MMR_line.png"),height=900,width=1200)
MMR_line
dev.off()
cbhmis_agg <- cbhmis_lga %>%
select(LGA,repRate,ANC_ref,lb,deaths,wra_pop) %>%
group_by(LGA) %>%
summarise(repRate = mean(repRate,na.rm=TRUE),
ANC_ref = mean(ANC_ref, na.rm=TRUE),
lb = sum(lb,na.rm = T),
deaths=sum(deaths, na.rm = T),
wra = max(wra_pop))
cbhmis_agg$ANC_ref_scaled <- 1000*cbhmis_agg$ANC_ref/cbhmis_agg$wra
cbhmis_agg$MMR <- 100000*cbhmis_agg$deaths/cbhmis_agg$lb
kdn_shp <- left_join(kdn_shp,cbhmis_agg,by=c("NAME_2"="LGA"))
pMMRmap <- ggplot(kdn_shp) +
geom_sf(aes(fill = MMR)) +
scale_fill_viridis_c() +
geom_sf_text(aes(label = NAME_2 ), size = 4, check_overlap = TRUE,color="white",fontface ="bold") +
theme_void() +
labs(fill = "MMR (per 100k LB)",
title = "MMR for period of Oct '23-Mar '25")
png(filename = paste0(outdir,"/plots/MMR_map.png"),height=1000,width=1200)
pMMRmap
dev.off()
pANCrefmap <- ggplot(kdn_shp) +
geom_sf(aes(fill = ANC_ref_scaled)) +
scale_fill_viridis_c() +
geom_sf_text(aes(label = NAME_2 ), size = 4, check_overlap = TRUE,color="white",fontface ="bold") +
theme_void() +
labs(fill = "ANC referrals (per 1000 WRA)",
title = "Average ANC referrals over Oct '23-Mar '25 period")
png(filename = paste0(outdir,"/plots/ANCref_map.png"),height=1000,width=1200)
pANCrefmap
dev.off()
educ <- read.csv("raw data/education_khhs.csv")
educ$LGA <- ifelse(educ$LGA=="MAKARFI","Makarfi",educ$LGA)
educ$LGA <- ifelse(educ$LGA=="ZANGON_KATAF","Zangon_Kataf",educ$LGA)
educ$LGA <- gsub(pattern = "_",replacement = " ",x = educ$LGA)
educ <- educ %>% select(LGA,ever_school,second.plus) %>%
mutate(ever_school=100*ever_school,
second.plus=100*second.plus,
LGA = str_to_title(LGA, locale = "en"))
educ$LGA <- gsub(pattern = " ",replacement = "_",x = educ$LGA)
kdn_shp <- left_join(kdn_shp,educ,by=c("NAME_2"="LGA"))
pAnyEdmap <- ggplot(kdn_shp) +
geom_sf(aes(fill = ever_school )) +
scale_fill_viridis_c() +
geom_sf_text(aes(label = NAME_2 ), size = 4, check_overlap = TRUE,color="white",fontface ="bold") +
theme_void() +
labs(fill = "Proportion",
title = "Women who have attended any school")
pSecondmap <- ggplot(kdn_shp) +
geom_sf(aes(fill = second.plus )) +
scale_fill_viridis_c() +
geom_sf_text(aes(label = NAME_2 ), size = 4, check_overlap = TRUE,color="white",fontface ="bold") +
theme_void() +
labs(fill = "Proportion",
title = "Women who attended secondary or higher")
educ_map <- pAnyEdmap + pSecondmap + plot_layout(ncol = 2)
png(filename = paste0(outdir,"/plots/educ_map.png"),height=900,width=1200)
educ_map
dev.off()
##### D2: Travel time from Malaria Atlas project #####
## We want to calculate average or median travel time using the MAP data
## cite: https://www.nature.com/articles/s41591-020-1059-1
## To aggregate to LGA level we need to appropriately weight by population
## Using GRID3 population data to do this
kaduna_vect <- vect(kdn_shp)
# travel time to health facility by motor
tt_raster <- rast("raw data/travel time/202001_Global_Motorized_Travel_Time_to_Healthcare_NGA.tiff")
kdn_shp$tt_mean_unweighted <- exact_extract(tt_raster, kdn_shp, 'mean')
pTTmap <- ggplot(kdn_shp) +
geom_sf(aes(fill = tt_mean_unweighted )) +
scale_fill_viridis_c() +
geom_sf_text(aes(label = NAME_2 ), size = 4, check_overlap = TRUE,color="white",fontface ="bold") +
theme_void() +
labs(fill = "Travel Time (min)",
title = "Unweighted travel time to nearest facility")
png(filename = paste0(outdir,"/plots/traveltime_map.png"),height=900,width=1200)
pTTmap
dev.off()
##### D3: ANC volumes #####
## HMIS data sent by Hadiza
hmis_full <- readxl::read_excel("raw data/Modeldata-IDMCHAI_02032025.xls")
names(hmis_full) <- gsub(pattern = " ",replacement = ".",x=names(hmis_full))
anc <- hmis_full[,c("organisationunitname",grep(pattern = "ANC",x = names(hmis_full),value = TRUE))]
anc
anc$LGA <- anc$organisationunitname
anc$LGA <- trimws(gsub("kd | Local Government Area","",anc$LGA))
anc$LGA <- gsub(" ",replacement = "_",anc$LGA)
anc$LGA <- gsub("'",replacement = "",anc$LGA)
## Converting from wide to long for easy average
anc_long <- anc %>%
pivot_longer(
cols = matches("^ANC\\."),
names_to = c("visit_type", "month"),
names_pattern = "^(ANC\\.[^\\.]+)\\.*[Vv]isit\\.*(.*)$",
values_to = "value"
) %>%
mutate(
# Normalize and parse month names
month = str_replace_all(month, "\\.+", "."),
date = parse_date_time(month, orders = "my", locale = "en_US")
)
anc_long
anc
pANCvis <- ggplot(anc_long, aes(x = date, y = value, color = visit_type)) +
geom_line(na.rm = TRUE) +
geom_point(na.rm = TRUE) +
facet_wrap(~ LGA, scales = "free_y") +
labs(
title = "ANC Visit Trends by LGA",
x = "Date",
y = "Number of Visits",
color = "Visit Type"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "bottom"
)
pANCvis
anc_long
anc
anc_long
ancAvg <- anc_long %>%
group_by(visit_type, LGA) %>%
summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
ancAvg
ancAvg
ancAvg
ancAvg
ancAvg
wra_pop
pop_wra
ancAvg <- left_join(ancAvg,pop_dat,by=c("LGA"="NAME_2"))
ancAvg
View(ancAvg)
ancAvg$val_std <- ancAvg$value/ancAvg$wra_pop
ancAvg$val_std
ancAvg$val_std <- ancAvg$value/ancAvg$wra_pop * 1000
ancAvg$val_std
ancAvg <- ancAvg %>%
pivot_wider(
names_from = visit_type,
values_from = val_std
)
ancAvg
ancAvg <- left_join(ancAvg,pop_dat,by=c("LGA"="NAME_2"))
## Calculate average over the observation period and standardize by WRA pop
ancAvg <- anc_long %>%
group_by(visit_type, LGA) %>%
summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
ancAvg <- left_join(ancAvg,pop_dat,by=c("LGA"="NAME_2"))
View(ancAvg)
ancAvg$val_std <- ancAvg$value/ancAvg$wra_pop * 1000
View(ancAvg)
ancAvg
ancAvg <- ancAvg %>%
pivot_wider(
names_from = visit_type,
values_from = val_std
)
ancAvg
ancAvg <- anc_long %>%
group_by(visit_type, LGA) %>%
summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
ancAvg <- left_join(ancAvg,pop_dat,by=c("LGA"="NAME_2"))
ancAvg$val_std <- ancAvg$value/ancAvg$wra_pop * 1000
ancAvg
View(ancAvg)
## convert to wide
ancAvg <- ancAvg %>%
spread(visit_type, val_std)
ancAvg
ancAvg
ancAvg <- anc_long %>%
group_by(visit_type, LGA) %>%
summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
ancAvg <- left_join(ancAvg,pop_dat,by=c("LGA"="NAME_2"))
ancAvg$val_std <- ancAvg$value/ancAvg$wra_pop * 1000
ancAvg
## convert to wide
ancAvg <- ancAvg %>% select(LGA,visit_type,val_std) %>% spread(visit_type, val_std)
ancAvg
pred1 <- st_drop_geometry(kdn_shp[,c("NAME_2","ever_school","second.plus","tt_mean_unweighted")])
cbhmis_final <- left_join(cbhmis_agg,pred1,by=c("LGA"="NAME_2"))
cbhmis_final <- left_join(cbhmis_final,ancAvg,by=c("LGA"))
write.csv(cbhmis_final,"cbhmis_data_for_model.csv",row.names = F)
#################################################################
library(sf)
library(spdep)
rm(list=ls())
set.seed(105)
setwd("C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR")
outdir <- "C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR/output/"
#### 1: Read in data ####
modDate <- read.csv("cbhmis_data_for_model.csv")
## define Outcome and offset
# ------------------------
z <- modDate$deaths
live_births <- modDate$lb
N <- length(z)  # number of LGAs
#### 2: Center and covariates  ####
incidence_covars <- scale(modDate[, c("ever_school", "tt_mean_unweighted", "ANC.4th")],
center = TRUE, scale = FALSE)
# Reporting model covariate: center
reporting_covars <- scale(modDate[, "ANC_ref_scaled", drop = FALSE],
center = TRUE, scale = FALSE)
#### 3: Create spatial inputs  ####
nga_shp <- st_read("raw data/gadm41_NGA_shp/gadm41_NGA_2.shp")
kdn_shp <- nga_shp[nga_shp$NAME_1=="Kaduna",]
kdn_shp$NAME_2 <- gsub(pattern = " ",replacement = "_", kdn_shp$NAME_2)
kdn_shp$NAME_2 <- gsub(pattern = "'",replacement = "", kdn_shp$NAME_2)
nb <- poly2nb(kdn_shp)
incidence_covars
reporting_covars
#### 3: Create spatial inputs  ####
nga_shp <- st_read("raw data/gadm41_NGA_shp/gadm41_NGA_2.shp")
kdn_shp <- nga_shp[nga_shp$NAME_1=="Kaduna",]
kdn_shp$NAME_2 <- gsub(pattern = " ",replacement = "_", kdn_shp$NAME_2)
kdn_shp$NAME_2 <- gsub(pattern = "'",replacement = "", kdn_shp$NAME_2)
nb <- poly2nb(kdn_shp)
lw <- nb2listw(nb, style = "B", zero.policy = TRUE)  # binary style
# Extract NIMBLE structures
adj <- unlist(nb)
num <- sapply(nb, length)
weights <- rep(1, length(adj))
l_adj <- length(adj)
nimble_constants <- list(
n = N,
R = N,
adj = adj,
num = num,
weights = weights,
l_adj = l_adj
)
nimble_data <- list(
z = z,
educ = incidence_covars[, 1],
travel = incidence_covars[, 2],
anc4 = incidence_covars[, 3],
ancRef = reporting_covars[, 1],
live_births = live_births
)
### Intial values -- REALLY SHOULD DO ONE PER CHAIN
nimble_inits <- list(
a = c(0, 0, 0, 0),  # intercept + 3 incidence covariates
b = c(2, 0),         # intercept + 1 reporting covariate
sigma = 0.5,
epsilon = 0.5,
nu = 0.5,
phi = rnorm(N, 0, 1),
theta = rnorm(N, 0, 0.5),
gamma = rnorm(N, 0, 0.5)
)
#### 3: Save NIMBLE data  ####
save(nimble_constants, nimble_data, nimble_inits, file = "nimble_inputs_final.RData")
#################################################################
##   LGA estimates of community MMR                            ##
##   2. RUN_NIMBLE                                             ##
##   Purpose: Run model using NIMBLE                           ##
##   Author: Anu Mishra                                        ##
##   Created 6/9/25                                            ##
#################################################################
library(nimble)
rm(list=ls())
start_time <- Sys.time()
set.seed(105)
setwd("C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR")
outdir <- "C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR/output/"
#### Load NIMBLE data
load("nimble_inputs_final.RData")
# --- Model code block ---
mmr_code <- nimbleCode({
for (i in 1:n) {
# Under-reporting model (logit scale)
pi[i] <- ilogit(b[1] + ancRef[i] * b[2] + gamma[i])
# Incidence model (log scale)
lambda[i] <- exp(log(live_births[i]) +
a[1] + educ[i] * a[2] +
travel[i] * a[3] + anc4[i] * a[4] +
phi[i] + theta[i])
# Likelihood for observed deaths
z[i] ~ dpois(pi[i] * lambda[i])
# Observation-level noise in reporting probability
gamma[i] ~ dnorm(0, sd = epsilon)
}
# Unstructured spatial effect (iid)
for (j in 1:R) {
theta[j] ~ dnorm(0, sd = sigma)
}
# Structured spatial effect (ICAR)
phi[1:R] ~ dcar_normal(adj = adj[1:l_adj], num = num[1:R], tau = tau, zero_mean = 1)
# Priors: incidence coefficients
for (k in 1:4) {
a[k] ~ dnorm(0, sd = 10)  # vague priors for all
}
# Priors: reporting coefficients
b[1] ~ dnorm(2, sd = 0.6)   # informative prior on reporting rate
b[2] ~ dnorm(0, sd = 10)
# Priors: variance parameters
sigma ~ T(dnorm(0, 1), 0, )
epsilon ~ T(dnorm(0, 1), 0, )
nu ~ T(dnorm(0, 1), 0, )
tau <- 1 / (nu^2)
})
library(nimble)
rm(list=ls())
start_time <- Sys.time()
set.seed(105)
setwd("C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR")
outdir <- "C:/Users/anumi/OneDrive - Bill & Melinda Gates Foundation/Documents/GitHub/CBHMIS_SAE_MMR/output/"
#### Load NIMBLE data
load("nimble_inputs_final.RData")
# --- Model code block ---
mmr_code <- nimbleCode({
for (i in 1:n) {
# Under-reporting model (logit scale)
pi[i] <- ilogit(b[1] + ancRef[i] * b[2] + gamma[i])
# Incidence model (log scale)
lambda[i] <- exp(log(live_births[i]) +
a[1] + educ[i] * a[2] +
travel[i] * a[3] + anc4[i] * a[4] +
phi[i] + theta[i])
# Likelihood for observed deaths
z[i] ~ dpois(pi[i] * lambda[i])
# Observation-level noise in reporting probability
gamma[i] ~ dnorm(0, sd = epsilon)
}
# Unstructured spatial effect (iid)
for (j in 1:R) {
theta[j] ~ dnorm(0, sd = sigma)
}
# Structured spatial effect (ICAR)
phi[1:R] ~ dcar_normal(adj = adj[1:l_adj], num = num[1:R], tau = tau, zero_mean = 1)
# Priors: incidence coefficients
for (k in 1:4) {
a[k] ~ dnorm(0, sd = 10)  # vague priors for all
}
# Priors: reporting coefficients
b[1] ~ dnorm(2, sd = 0.6)   # informative prior on reporting rate
b[2] ~ dnorm(0, sd = 10)
# Priors: variance parameters
sigma ~ T(dnorm(0, 1), 0, )
epsilon ~ T(dnorm(0, 1), 0, )
nu ~ T(dnorm(0, 1), 0, )
tau <- 1 / (nu^2)
})
# --- Build and compile model ---
mmr_model <- nimbleModel(mmr_code, constants = nimble_constants, data = nimble_data, inits = nimble_inits)
compiled_model <- compileNimble(mmr_model)
# --- Configure MCMC ---
### DECIDE IF WANT WAIC here
mmr_conf <- configureMCMC(mmr_model,
monitors = c("a", "b", "sigma", "epsilon", "tau", "phi", "theta", "pi", "lambda"),
useConjugacy = TRUE,enableWAIC = TRUE)
# Customize samplers (e.g., slice sampling for highly correlated terms) -- Not sure if I need this, but following STONER paper
mmr_conf$removeSamplers(c("a[1]", "b[1]", "sigma", "nu", "epsilon"))
mmr_conf$addSampler(target = c("a[1]", "b[1]", "epsilon"), type = "AF_slice")
mmr_conf$addSampler(target = c("sigma", "nu"), type = "AF_slice")
# --- Compile and run MCMC ---
mmr_mcmc <- buildMCMC(mmr_conf)
compiled_mcmc <- compileNimble(mmr_mcmc, project = mmr_model)
samples <- runMCMC(compiled_mcmc,
nchains = 4,
niter = 200,
nburnin = 5,
thin = 1,
summary = FALSE,
samplesAsCodaMCMC = TRUE,
WAIC = TRUE)
